densenet121
PYTORCH_MODEL=False
BATCH_SIZE=16
EPOCHS=200
Adam params:
LEARNING_RATE=0.0001
WEIGHT_DECAY=0
BETAS=(0.9, 0.999)
EPS=1e-08
Epoch [1/200], Loss: 1.93379402
Epoch [2/200], Loss: 0.73538691
Epoch [3/200], Loss: 0.55659944
Epoch [4/200], Loss: 0.32020187
Epoch [5/200], Loss: 0.16703142
Epoch [6/200], Loss: 0.30755353
Epoch [7/200], Loss: 0.15691070
Epoch [8/200], Loss: 0.10368182
Epoch [9/200], Loss: 0.06331846
Epoch [10/200], Loss: 0.06120067
Epoch [11/200], Loss: 0.05576817
Epoch [12/200], Loss: 0.07786027
Epoch [13/200], Loss: 0.31837866
Epoch [14/200], Loss: 0.03619963
Epoch [15/200], Loss: 0.06156868
Epoch [16/200], Loss: 0.07551952
Epoch [17/200], Loss: 0.03226922
Epoch [18/200], Loss: 0.04026534
Epoch [19/200], Loss: 0.02356846
Epoch [20/200], Loss: 0.08963455
Epoch [21/200], Loss: 0.06282939
Epoch [22/200], Loss: 0.01531715
Epoch [23/200], Loss: 0.01884902
Epoch [24/200], Loss: 0.05578378
Epoch [25/200], Loss: 0.03181854
Epoch [26/200], Loss: 0.01860821
Epoch [27/200], Loss: 0.01133373
Epoch [28/200], Loss: 0.01641051
Epoch [29/200], Loss: 0.03650010
Epoch [30/200], Loss: 0.01063170
Epoch [31/200], Loss: 0.00958203
Epoch [32/200], Loss: 0.02902610
Epoch [33/200], Loss: 0.02490526
Epoch [34/200], Loss: 0.00741550
Epoch [35/200], Loss: 0.02696839
Epoch [36/200], Loss: 0.00842914
Epoch [37/200], Loss: 0.00934917
Epoch [38/200], Loss: 0.00896175
Epoch [39/200], Loss: 0.00623955
Epoch [40/200], Loss: 0.00867747
Epoch [41/200], Loss: 0.02254185
Epoch [42/200], Loss: 0.02578848
Epoch [43/200], Loss: 0.02013990
Epoch [44/200], Loss: 0.05877476
Epoch [45/200], Loss: 0.00495785
Epoch [46/200], Loss: 0.01076723
Epoch [47/200], Loss: 0.00514092
Epoch [48/200], Loss: 0.02623281
Epoch [49/200], Loss: 0.02106313
Epoch [50/200], Loss: 0.02122645
Epoch [51/200], Loss: 0.01497873
Epoch [52/200], Loss: 0.00346662
Epoch [53/200], Loss: 0.01178354
Epoch [54/200], Loss: 0.00868586
Epoch [55/200], Loss: 0.02299833
Epoch [56/200], Loss: 0.01404054
Epoch [57/200], Loss: 0.01743200
Epoch [58/200], Loss: 0.02017738
Epoch [59/200], Loss: 0.00819620
Epoch [60/200], Loss: 0.01141225
Epoch [61/200], Loss: 0.00267308
Epoch [62/200], Loss: 0.01164594
Epoch [63/200], Loss: 0.00263897
Epoch [64/200], Loss: 0.00513657
Epoch [65/200], Loss: 0.00298978
Epoch [66/200], Loss: 0.00237454
Epoch [67/200], Loss: 0.07253034
Epoch [68/200], Loss: 0.00450177
Epoch [69/200], Loss: 0.00900676
Epoch [70/200], Loss: 0.00449083
Epoch [71/200], Loss: 0.00269310
Epoch [72/200], Loss: 0.00232629
Epoch [73/200], Loss: 0.00755595
Epoch [74/200], Loss: 0.00235022
Epoch [75/200], Loss: 0.00215925
Epoch [76/200], Loss: 0.01151746
Epoch [77/200], Loss: 0.00778117
Epoch [78/200], Loss: 0.02727358
Epoch [79/200], Loss: 0.00340250
Epoch [80/200], Loss: 0.01707045
Epoch [81/200], Loss: 0.08145560
Epoch [82/200], Loss: 0.00427762
Epoch [83/200], Loss: 0.03311437
Epoch [84/200], Loss: 0.00319271
Epoch [85/200], Loss: 0.00355527
Epoch [86/200], Loss: 0.00851145
Epoch [87/200], Loss: 0.00220496
Epoch [88/200], Loss: 0.00261131
Epoch [89/200], Loss: 0.01715667
Epoch [90/200], Loss: 0.00900122
Epoch [91/200], Loss: 0.00441489
Epoch [92/200], Loss: 0.06588791
Epoch [93/200], Loss: 0.47213382
Epoch [94/200], Loss: 0.18457036
Epoch [95/200], Loss: 0.01570460
Epoch [96/200], Loss: 0.00985758
Epoch [97/200], Loss: 0.02849170
Epoch [98/200], Loss: 0.01501013
Epoch [99/200], Loss: 0.00382655
Epoch [100/200], Loss: 0.01508570
Epoch [101/200], Loss: 0.00387471
Epoch [102/200], Loss: 0.00545691
Epoch [103/200], Loss: 0.00483243
Epoch [104/200], Loss: 0.00141407
Epoch [105/200], Loss: 0.01299741
Epoch [106/200], Loss: 0.01566250
Epoch [107/200], Loss: 0.02369642
Epoch [108/200], Loss: 0.00112371
Epoch [109/200], Loss: 0.00595522
Epoch [110/200], Loss: 0.00619903
Epoch [111/200], Loss: 0.00116739
Epoch [112/200], Loss: 0.00105622
Epoch [113/200], Loss: 0.00896212
Epoch [114/200], Loss: 0.00083031
Epoch [115/200], Loss: 0.00619759
Epoch [116/200], Loss: 0.00093585
Epoch [117/200], Loss: 0.00119273
Epoch [118/200], Loss: 0.00097092
Epoch [119/200], Loss: 0.00344811
Epoch [120/200], Loss: 0.00082156
Epoch [121/200], Loss: 0.00420476
Epoch [122/200], Loss: 0.00762299
Epoch [123/200], Loss: 0.00206289
Epoch [124/200], Loss: 0.00499426
Epoch [125/200], Loss: 0.00307370
Epoch [126/200], Loss: 0.00367036
Epoch [127/200], Loss: 0.01264314
Epoch [128/200], Loss: 0.00191282
Epoch [129/200], Loss: 0.00903614
Epoch [130/200], Loss: 0.00469297
Epoch [131/200], Loss: 0.00366668
Epoch [132/200], Loss: 0.00118619
Epoch [133/200], Loss: 0.07497567
Epoch [134/200], Loss: 0.00544242
Epoch [135/200], Loss: 0.00157981
Epoch [136/200], Loss: 0.00719574
Epoch [137/200], Loss: 0.08639282
Epoch [138/200], Loss: 0.00214654
Epoch [139/200], Loss: 0.00125495
Epoch [140/200], Loss: 0.00300728
Epoch [141/200], Loss: 0.00222489
Epoch [142/200], Loss: 0.00085274
Epoch [143/200], Loss: 0.00596663
Epoch [144/200], Loss: 0.00085508
Epoch [145/200], Loss: 0.00414993
Epoch [146/200], Loss: 0.01528256
Epoch [147/200], Loss: 0.00077073
Epoch [148/200], Loss: 0.00078031
Epoch [149/200], Loss: 0.00103187
Epoch [150/200], Loss: 0.01631644
Epoch [151/200], Loss: 0.00063681
Epoch [152/200], Loss: 0.00225461
Epoch [153/200], Loss: 0.00037747
Epoch [154/200], Loss: 0.00386108
Epoch [155/200], Loss: 0.00611462
Epoch [156/200], Loss: 0.00054825
Epoch [157/200], Loss: 0.00239633
Epoch [158/200], Loss: 0.00064416
Epoch [159/200], Loss: 0.00051749
Epoch [160/200], Loss: 0.00083893
Epoch [161/200], Loss: 0.00034077
Epoch [162/200], Loss: 0.00043961
Epoch [163/200], Loss: 0.00041464
Epoch [164/200], Loss: 0.00065708
Epoch [165/200], Loss: 0.00063936
Epoch [166/200], Loss: 0.00043928
Epoch [167/200], Loss: 0.00259021
Epoch [168/200], Loss: 0.00120910
Epoch [169/200], Loss: 0.00044336
Epoch [170/200], Loss: 0.00347860
Epoch [171/200], Loss: 0.04053375
Epoch [172/200], Loss: 0.00041728
Epoch [173/200], Loss: 0.00110397
Epoch [174/200], Loss: 0.00052350
Epoch [175/200], Loss: 0.00360670
Epoch [176/200], Loss: 0.02249928
Epoch [177/200], Loss: 0.01216473
Epoch [178/200], Loss: 0.00672117
Epoch [179/200], Loss: 0.00977917
Epoch [180/200], Loss: 0.01003118
Epoch [181/200], Loss: 0.00271059
Epoch [182/200], Loss: 0.01193321
Epoch [183/200], Loss: 0.00076648
Epoch [184/200], Loss: 0.00119354
Epoch [185/200], Loss: 0.00391343
Epoch [186/200], Loss: 0.00250659
Epoch [187/200], Loss: 0.02343974
Epoch [188/200], Loss: 0.00797405
Epoch [189/200], Loss: 0.00751314
Epoch [190/200], Loss: 0.01315873
Epoch [191/200], Loss: 0.00219417
Epoch [192/200], Loss: 0.00048988
Epoch [193/200], Loss: 0.00410462
Epoch [194/200], Loss: 0.00043932
Epoch [195/200], Loss: 0.00310089
Epoch [196/200], Loss: 0.00707177
Epoch [197/200], Loss: 0.00395024
Epoch [198/200], Loss: 0.00264803
Epoch [199/200], Loss: 0.00038419
Epoch [200/200], Loss: 0.00024853
best loss:0.00024852738715708256 at epoch 200
Accuracy=79.3103448275862% on dataset_custom/test
Accuracy=100.0% on dataset_custom2/test
